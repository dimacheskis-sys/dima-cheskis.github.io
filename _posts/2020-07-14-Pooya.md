---
layout: post
title: "Training with Adversaries to Improve Faithfulness of Attention in Neural Machine Translation"
root: ../../
---
In our lab meeting tomorrow, Pooya will practice his thesis defence.
A Zoom link will be posted to Twist on the morning of the meeting. 

**Training with Adversaries to Improve Faithfulness of Attention in Neural Machine Translation**

**Abstract:**
 Can we trust that the attention heatmaps produced by a neural machine translation (NMT) model reflect its true internal reasoning? We isolate and examine in detail the notion of faithfulness in NMT models.  We provide a measure of faithfulness for NMT based on a variety of stress tests where model parameters are perturbed and measuring faithfulness based on how often the model output changes. We show that our proposed faithfulness measure for NMT models can be improved using a novel differentiable objective that rewards faithful behaviour by the model through probability divergence. Our experimental results on multiple language pairs show that our objective function is effective in increasing faithfulness and can lead to a useful analysis of NMT model behaviour and more trustworthy attention heatmaps. Our proposed objective improves faithfulness without reducing the translation quality and it also seems to have a useful regularization effect on the NMT model and can even improve translation quality in some cases.

Tuesday, July 14th, 09:30 a.m.
